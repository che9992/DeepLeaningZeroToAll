{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9 \n",
    "## Back propagation<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/che/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is it possible XOR with logistic regression ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X:x_data, Y:y_data}),'\\n', sess.run(W))\n",
    "            \n",
    "    \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {X:x_data, Y:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Yn = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(Xn, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Yn * tf.log(hypothesis) + (1 - Yn) * tf.log(1 - hypothesis))\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Yn), tf.float32))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {Xn: x_data, Yn: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {Xn:x_data, Yn:y_data}),'\\n')\n",
    "            \n",
    "    \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {Xn:x_data, Yn:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Yw = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(Xw, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Yw * tf.log(hypothesis) + (1 - Yw) * tf.log(1 - hypothesis))\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Yw), tf.float32))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {Xw: x_data, Yw: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {Xw:x_data, Yw:y_data}),'\\n')\n",
    "            \n",
    "    \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {Xw:x_data, Yw:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Yd = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "Wd1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "bd1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(Xd, Wd1) + bd1)\n",
    "\n",
    "Wd2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "bd2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, Wd2) + bd2)\n",
    "\n",
    "Wd3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "bd3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, Wd3) + bd3)\n",
    "\n",
    "Wd4 = tf.Variable(tf.random_normal([10, 10]), name='weight4')\n",
    "bd4 = tf.Variable(tf.random_normal([10]), name='bias4')\n",
    "layer4 = tf.sigmoid(tf.matmul(layer3, Wd4) + bd4)\n",
    "\n",
    "Wd5 = tf.Variable(tf.random_normal([10, 1]), name='weight5')\n",
    "bd5 = tf.Variable(tf.random_normal([1]), name='bias5')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer4, Wd5) + bd5)\n",
    "\n",
    "cost = -tf.reduce_mean(Yd * tf.log(hypothesis) + (1 - Yd) * tf.log(1 - hypothesis))\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Yd), tf.float32))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {Xd: x_data, Yd: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {Xd:x_data, Yd:y_data}),'\\n')\n",
    "            \n",
    "    \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {Xd:x_data, Yd:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 10 of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8771527 \n",
      "\n",
      "200 0.6945456 \n",
      "\n",
      "400 0.6932262 \n",
      "\n",
      "600 0.6932186 \n",
      "\n",
      "800 0.69321835 \n",
      "\n",
      "1000 0.69321823 \n",
      "\n",
      "1200 0.69321805 \n",
      "\n",
      "1400 0.6932179 \n",
      "\n",
      "1600 0.6932177 \n",
      "\n",
      "1800 0.6932175 \n",
      "\n",
      "2000 0.69321734 \n",
      "\n",
      "2200 0.69321716 \n",
      "\n",
      "2400 0.69321704 \n",
      "\n",
      "2600 0.69321686 \n",
      "\n",
      "2800 0.6932167 \n",
      "\n",
      "3000 0.69321644 \n",
      "\n",
      "3200 0.6932163 \n",
      "\n",
      "3400 0.69321615 \n",
      "\n",
      "3600 0.69321597 \n",
      "\n",
      "3800 0.6932157 \n",
      "\n",
      "4000 0.6932156 \n",
      "\n",
      "4200 0.69321555 \n",
      "\n",
      "4400 0.69321525 \n",
      "\n",
      "4600 0.6932152 \n",
      "\n",
      "4800 0.69321495 \n",
      "\n",
      "5000 0.6932148 \n",
      "\n",
      "5200 0.69321465 \n",
      "\n",
      "5400 0.6932145 \n",
      "\n",
      "5600 0.6932143 \n",
      "\n",
      "5800 0.6932142 \n",
      "\n",
      "6000 0.69321406 \n",
      "\n",
      "6200 0.6932138 \n",
      "\n",
      "6400 0.69321376 \n",
      "\n",
      "6600 0.6932136 \n",
      "\n",
      "6800 0.69321334 \n",
      "\n",
      "7000 0.6932132 \n",
      "\n",
      "7200 0.6932131 \n",
      "\n",
      "7400 0.69321287 \n",
      "\n",
      "7600 0.69321275 \n",
      "\n",
      "7800 0.6932126 \n",
      "\n",
      "8000 0.69321245 \n",
      "\n",
      "8200 0.6932123 \n",
      "\n",
      "8400 0.69321215 \n",
      "\n",
      "8600 0.69321203 \n",
      "\n",
      "8800 0.6932118 \n",
      "\n",
      "9000 0.6932116 \n",
      "\n",
      "9200 0.6932116 \n",
      "\n",
      "9400 0.6932113 \n",
      "\n",
      "9600 0.6932113 \n",
      "\n",
      "9800 0.6932111 \n",
      "\n",
      "10000 0.69321096 \n",
      "\n",
      "\n",
      "hypothesis:\n",
      " [[0.5001608 ]\n",
      " [0.50008535]\n",
      " [0.4998673 ]\n",
      " [0.49991935]] \n",
      "correct: 0.69321096 \n",
      "accuracy: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "#input\n",
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "\n",
    "#hidden\n",
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "W4 = tf.Variable(tf.random_normal([10, 10]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([10]), name='bias4')\n",
    "W5 = tf.Variable(tf.random_normal([10, 10]), name='weight5')\n",
    "b5 = tf.Variable(tf.random_normal([10]), name='bias5')\n",
    "W6 = tf.Variable(tf.random_normal([10, 10]), name='weight6')\n",
    "b6 = tf.Variable(tf.random_normal([10]), name='bias6')\n",
    "W7 = tf.Variable(tf.random_normal([10, 10]), name='weight7')\n",
    "b7 = tf.Variable(tf.random_normal([10]), name='bias7')\n",
    "W8 = tf.Variable(tf.random_normal([10, 10]), name='weight8')\n",
    "b8 = tf.Variable(tf.random_normal([10]), name='bias8')\n",
    "W9 = tf.Variable(tf.random_normal([10, 10]), name='weight9')\n",
    "b9 = tf.Variable(tf.random_normal([10]), name='bias9')\n",
    "W10 = tf.Variable(tf.random_normal([10, 10]), name='weight10')\n",
    "b10 = tf.Variable(tf.random_normal([10]), name='bias19')\n",
    "\n",
    "#output\n",
    "W11 = tf.Variable(tf.random_normal([10, 1]), name='weight11')\n",
    "b11 = tf.Variable(tf.random_normal([1]), name='bias11')\n",
    "\n",
    "with tf.name_scope('layer1') as scope:\n",
    "    L1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "with tf.name_scope('layer2') as scope:\n",
    "    L2 = tf.sigmoid(tf.matmul(L1,W2) + b2)\n",
    "with tf.name_scope('layer3') as scope:\n",
    "    L3 = tf.sigmoid(tf.matmul(L2,W3) + b3)\n",
    "with tf.name_scope('layer4') as scope:\n",
    "    L4 = tf.sigmoid(tf.matmul(L3,W4) + b4)\n",
    "with tf.name_scope('layer5') as scope:\n",
    "    L5 = tf.sigmoid(tf.matmul(L4,W5) + b5)\n",
    "with tf.name_scope('layer6') as scope:\n",
    "    L6 = tf.sigmoid(tf.matmul(L5,W6) + b6)\n",
    "with tf.name_scope('layer7') as scope:\n",
    "    L7 = tf.sigmoid(tf.matmul(L6,W7) + b7)\n",
    "with tf.name_scope('layer8') as scope:\n",
    "    L8 = tf.sigmoid(tf.matmul(L7,W8) + b8)\n",
    "with tf.name_scope('layer9') as scope:\n",
    "    L9 = tf.sigmoid(tf.matmul(L8,W9) + b9)\n",
    "with tf.name_scope('layer10') as scope:\n",
    "    L10 = tf.sigmoid(tf.matmul(L9,W10) + b10)\n",
    "    \n",
    "with tf.name_scope('hypothesis') as scope:\n",
    "    hypothesis = tf.sigmoid(tf.matmul(L10,W11) + b11)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X:x_data, Y:y_data}),'\\n')\n",
    "            \n",
    "    \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {X:x_data, Y:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But! there are Vanishing gradient problem !\n",
    "### Using ReLU instead of sigmoid\n",
    "<hr/>\n",
    "```python \n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1 ) XXXXXXX\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1 )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6932213 \n",
      "\n",
      "200 0.6931377 \n",
      "\n",
      "400 0.6928458 \n",
      "\n",
      "600 0.69170374 \n",
      "\n",
      "800 0.6908662 \n",
      "\n",
      "1000 0.68986845 \n",
      "\n",
      "1200 0.68831086 \n",
      "\n",
      "1400 0.6855862 \n",
      "\n",
      "1600 0.67968464 \n",
      "\n",
      "1800 0.6345488 \n",
      "\n",
      "2000 0.37622005 \n",
      "\n",
      "2200 0.13137312 \n",
      "\n",
      "2400 0.050575152 \n",
      "\n",
      "2600 0.019695895 \n",
      "\n",
      "2800 0.009526575 \n",
      "\n",
      "3000 0.0055656056 \n",
      "\n",
      "3200 0.0036883596 \n",
      "\n",
      "3400 0.0026581695 \n",
      "\n",
      "3600 0.0020304052 \n",
      "\n",
      "3800 0.0016163479 \n",
      "\n",
      "4000 0.0013275282 \n",
      "\n",
      "4200 0.0011167963 \n",
      "\n",
      "4400 0.00095748744 \n",
      "\n",
      "4600 0.0008336296 \n",
      "\n",
      "4800 0.0007351548 \n",
      "\n",
      "5000 0.0006551111 \n",
      "\n",
      "5200 0.00058914826 \n",
      "\n",
      "5400 0.0005339196 \n",
      "\n",
      "5600 0.0004870948 \n",
      "\n",
      "5800 0.00044698603 \n",
      "\n",
      "6000 0.00041239866 \n",
      "\n",
      "6200 0.00038219817 \n",
      "\n",
      "6400 0.00035569776 \n",
      "\n",
      "6600 0.00033227063 \n",
      "\n",
      "6800 0.00031143913 \n",
      "\n",
      "7000 0.0002927706 \n",
      "\n",
      "7200 0.00027602617 \n",
      "\n",
      "7400 0.0002608478 \n",
      "\n",
      "7600 0.00024716085 \n",
      "\n",
      "7800 0.00023462229 \n",
      "\n",
      "8000 0.00022323198 \n",
      "\n",
      "8200 0.00021273647 \n",
      "\n",
      "8400 0.00020312073 \n",
      "\n",
      "8600 0.00019420584 \n",
      "\n",
      "8800 0.00018597688 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "#input\n",
    "W1 = tf.Variable(tf.random_uniform([2, 5], -1.0, 1.0), name='weight1')\n",
    "b1 = tf.Variable(tf.zeros([5]), name='bias1')\n",
    "\n",
    "#hidden\n",
    "W2 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight2')\n",
    "b2 = tf.Variable(tf.zeros([5]), name='bias2')\n",
    "W3 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight3')\n",
    "b3 = tf.Variable(tf.zeros([5]), name='bias3')\n",
    "W4 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight4')\n",
    "b4 = tf.Variable(tf.zeros([5]), name='bias4')\n",
    "W5 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight5')\n",
    "b5 = tf.Variable(tf.zeros([5]), name='bias5')\n",
    "W6 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight6')\n",
    "b6 = tf.Variable(tf.zeros([5]), name='bias6')\n",
    "W7 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight7')\n",
    "b7 = tf.Variable(tf.zeros([5]), name='bias7')\n",
    "W8 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight8')\n",
    "b8 = tf.Variable(tf.zeros([5]), name='bias8')\n",
    "W9 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight9')\n",
    "b9 = tf.Variable(tf.zeros([5]), name='bias9')\n",
    "W10 = tf.Variable(tf.random_uniform([5, 5], -1.0, 1.0), name='weight10')\n",
    "b10 = tf.Variable(tf.zeros([5]), name='bias10')\n",
    "\n",
    "#output\n",
    "W11 = tf.Variable(tf.random_uniform([5, 1], -1.0, 1.0), name='weight11')\n",
    "b11 = tf.Variable(tf.zeros([1]), name='bias11')\n",
    "\n",
    "with tf.name_scope('layer1') as scope:\n",
    "    L1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "with tf.name_scope('layer2') as scope:\n",
    "    L2 = tf.nn.relu(tf.matmul(L1,W2) + b2)\n",
    "with tf.name_scope('layer3') as scope:\n",
    "    L3 = tf.nn.relu(tf.matmul(L2,W3) + b3)\n",
    "with tf.name_scope('layer4') as scope:\n",
    "    L4 = tf.nn.relu(tf.matmul(L3,W4) + b4)\n",
    "with tf.name_scope('layer5') as scope:\n",
    "    L5 = tf.nn.relu(tf.matmul(L4,W5) + b5)\n",
    "with tf.name_scope('layer6') as scope:\n",
    "    L6 = tf.nn.relu(tf.matmul(L5,W6) + b6)\n",
    "with tf.name_scope('layer7') as scope:\n",
    "    L7 = tf.nn.relu(tf.matmul(L6,W7) + b7)\n",
    "with tf.name_scope('layer8') as scope:\n",
    "    L8 = tf.nn.relu(tf.matmul(L7,W8) + b8)\n",
    "with tf.name_scope('layer9') as scope:\n",
    "    L9 = tf.nn.relu(tf.matmul(L8,W9) + b9)\n",
    "with tf.name_scope('layer10') as scope:\n",
    "    L10 = tf.nn.relu(tf.matmul(L9,W10) + b10)\n",
    "    \n",
    "with tf.name_scope('hypothesis') as scope:\n",
    "    hypothesis = tf.sigmoid(tf.matmul(L10,W11) + b11)\n",
    "    \n",
    "    \n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), tf.float32))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X:x_data, Y:y_data}),'\\n')\n",
    "     \n",
    "    h, c, a  = sess.run([hypothesis, cost, accuracy], feed_dict = {X:x_data, Y:y_data})\n",
    "    \n",
    "    print(\"\\nhypothesis:\\n\", h, \"\\ncorrect:\",c ,\"\\naccuracy:\",a *100 ,'%')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
